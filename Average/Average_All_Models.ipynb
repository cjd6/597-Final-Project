{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LC6M16LsR0ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMGXRqLSA6cD"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Average, Dense, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout, Activation, Input, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import efficientnet_v2, VGG16, ResNet50,InceptionResNetV2, InceptionV3\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QX8F9W2KBDut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2022\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "ZKdF5tL_BKs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = \"drive/MyDrive/Food_Grading2/train\"\n",
        "val_directory = \"drive/MyDrive/Food_Grading2/val\"\n",
        "test_directory = \"drive/MyDrive/Food_Grading2/test\""
      ],
      "metadata": {
        "id": "DqHH9iasBOtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=15, width_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "kSaHYgSWRdQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_directory,\n",
        "target_size=(256,256),\n",
        "color_mode='rgb',\n",
        "batch_size=32,\n",
        "class_mode='binary',\n",
        "subset='training',\n",
        "shuffle=True,\n",
        "seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRZbwvEXRgq6",
        "outputId": "e60071af-1ed0-4765-cd81-62bb7bfce2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4804 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "test_directory,\n",
        "target_size=(256,256),\n",
        "color_mode='rgb',\n",
        "batch_size=32,\n",
        "class_mode='binary',\n",
        "shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PyllQLIRisf",
        "outputId": "11b10a02-2ff4-47e1-fd3e-95539bec1070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1031 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = test_datagen.flow_from_directory(\n",
        "val_directory,\n",
        "target_size=(256,256),\n",
        "color_mode='rgb',\n",
        "batch_size=32,\n",
        "class_mode='binary',\n",
        "shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A81Rfr4jRkeh",
        "outputId": "b279dc29-d6fb-48ea-ed44-5ef2b617107e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1030 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3) #Cifar10 image size\n",
        "resized_shape = (224, 224, 3) #EfficientNetV2B0 model input shape\n",
        "num_classes = 1\n",
        "\n",
        "def build_Inception():\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, resized_shape[:2]))(inputs) #Resize image to  size 224x224\n",
        "    base_model = InceptionV3(include_top=False, input_shape=resized_shape, weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "    x = base_model(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    #model.trainable = False\n",
        "    return model\n",
        "def buildVGG():\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, resized_shape[:2]))(inputs) #Resize image to  size 224x224\n",
        "    base_model = VGG16(include_top=False, input_shape=resized_shape, weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "    x = base_model(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    #model.trainable = False\n",
        "    return model\n",
        "\n",
        "def buildEfficientnetV2S():\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, resized_shape[:2]))(inputs) #Resize image to  size 224x224\n",
        "    base_model = efficientnet_v2.EfficientNetV2S(include_top=False, input_shape=resized_shape, weights=\"imagenet\")\n",
        "    base_model.trainable = False\n",
        "    x = base_model(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    #model.trainable = False\n",
        "    return model"
      ],
      "metadata": {
        "id": "Qn1TGiBBRm6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = build_Inception()\n",
        "efficientnet = buildEfficientnetV2S()\n",
        "VGG16 = buildVGG()"
      ],
      "metadata": {
        "id": "gitfRUaa8-R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception.load_weights('/content/drive/MyDrive/Inceptionv3_Model.keras')\n",
        "efficientnet.load_weights('/content/drive/MyDrive/Efficientnet_V2S_Model.keras')\n",
        "VGG16.load_weights('/content/drive/MyDrive/VGGFinal.keras')"
      ],
      "metadata": {
        "id": "D6t35KGw-Lq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception.trainable = False\n",
        "efficientnet.trainable = False\n",
        "VGG16.trainable = False"
      ],
      "metadata": {
        "id": "WLb3G6M17z9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3) #Cifar10 image size\n",
        "resized_shape = (224, 224, 3) #EfficientNetV2B0 model input shape\n"
      ],
      "metadata": {
        "id": "dJpccT2-82Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [inception, efficientnet, VGG16]\n",
        "model_input = Input(shape=input_shape)\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble_output = Average()(model_outputs)\n",
        "model = Model(inputs=model_input, outputs=ensemble_output)"
      ],
      "metadata": {
        "id": "5M_RZGpe7Dvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plateau = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, patience=1, verbose=1)\n",
        "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1)\n",
        "\n",
        "model.compile(optimizer=optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "print(\"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "VUIDjj6zRp3N",
        "outputId": "87af6d31-16f9-4142-c808-04bf9f091717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │     \u001b[38;5;34m21,804,833\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │     \u001b[38;5;34m20,332,641\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_2 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │     \u001b[38;5;34m14,715,201\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (\u001b[38;5;33mAverage\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │                │ functional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                           │                        │                │ functional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,804,833</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,332,641</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,715,201</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ average (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │                │ functional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                           │                        │                │ functional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m56,852,675\u001b[0m (216.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,852,675</span> (216.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m56,852,675\u001b[0m (216.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,852,675</span> (216.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(test_generator, batch_size=32)\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "id": "1aUr3RJMRtJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70412f7-6683-4903-f2ad-f6de9c4b6ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate on test data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 14s/step - accuracy: 0.9822 - loss: 0.2606\n",
            "test loss, test acc: [0.28463831543922424, 0.9767216444015503]\n"
          ]
        }
      ]
    }
  ]
}